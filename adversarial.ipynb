{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import cvxpy as cx\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import optimize\n",
    "%matplotlib inline\n",
    "\n",
    "import tf_utils as tfu\n",
    "from load_data import *\n",
    "from features import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def solve_lp_down(C, nu, phi_x, y_true):\n",
    "    k = len(C)\n",
    "    y_down = cx.Variable(k)\n",
    "    y_up = cx.Variable(k)\n",
    "    v = cx.Variable()\n",
    "    u = cx.Variable()\n",
    "    ones = np.ones((k,1))\n",
    "    nu = nu.reshape((-1, 1))\n",
    "    \n",
    "    C_aug = C + ones.dot(nu.T).dot(phi_x - phi_x.dot(y_true).dot(ones.T))\n",
    "    constraints_down = [\n",
    "        v <= C_aug * y_down,\n",
    "        cx.sum_entries(y_down) == 1,\n",
    "        y_down >= 0,\n",
    "    ]\n",
    "    problem_down = cx.Problem(cx.Maximize(v), constraints_down)\n",
    "    problem_down.solve()\n",
    "\n",
    "    return y_down.value, v.value\n",
    "\n",
    "def solve_lp_up(C, nu, phi_x):\n",
    "    k = len(C)\n",
    "    y_up = cx.Variable(k)\n",
    "    u = cx.Variable()\n",
    "    ones = np.ones((k,1))\n",
    "    nu = nu.reshape((-1, 1))\n",
    "    C_aug = C + ones.dot(nu.T).dot(phi_x)\n",
    "    constraints = [\n",
    "        u >= y_up.T * C_aug,\n",
    "        cx.sum_entries(y_up) == 1,\n",
    "        y_up >= 0\n",
    "    ]\n",
    "    problem = cx.Problem(cx.Minimize(u), constraints)\n",
    "    problem.solve()\n",
    "    return y_up.value, u.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def phi_basic(X, k):\n",
    "    return np.stack([\n",
    "        [np.concatenate([np.outer(x,x).ravel() * (j == i) for j in range(k)])\n",
    "         for x in X] for i in range(k)\n",
    "        ], axis=2)\n",
    "\n",
    "def train_basic(X, Y, phi, opts):\n",
    "    (nx, dx), (ny, k) = X.shape, Y.shape\n",
    "    assert nx == ny\n",
    "\n",
    "    if opts.c_mode == 'random':                                            \n",
    "        C = np.random.uniform(size=(k, k))\n",
    "    elif opts.c_mode == 'ones':\n",
    "        C = np.ones((k, k))\n",
    "    else:\n",
    "        raise ValueError('C mode: %s' % opts.mode)\n",
    "    C[range(k), range(k)] = 0\n",
    "\n",
    "    # precompute phi since it does not change                                    \n",
    "    Phi_ndk = phi(X, k)\n",
    "    d = Phi_ndk.shape[1]\n",
    "    nu = np.zeros((d, 1))\n",
    "\n",
    "    def func_grad(nu):\n",
    "        f, g = 0, 0\n",
    "        for phi_x, y_true in zip(Phi_ndk, Y[..., None]):\n",
    "            # solve the inner LP                                                 \n",
    "            y_down_star, v = solve_lp_down(C, nu, phi_x, y_true)\n",
    "\n",
    "            # compute the subgradient\n",
    "            f += v\n",
    "            g += phi_x.dot(y_down_star - y_true)\n",
    "        return f / len(Y), g / len(Y)\n",
    "    \n",
    "    def callback(nu):\n",
    "        print func_grad(nu)[0]\n",
    "    \n",
    "    nu, v_star, info = optimize.fmin_l_bfgs_b(\n",
    "        func_grad, nu, callback=callback, pgtol=opts.tol, maxiter=opts.iters\n",
    "    )\n",
    "    info.pop('grad')\n",
    "    print v_star, info\n",
    "    \n",
    "    def classifier(X_bd):\n",
    "        Y = []\n",
    "        Phi_bdk = phi(X_bd, k)\n",
    "        for phi_x in Phi_bdk:\n",
    "            y_up_star, u = solve_lp_up(C, nu, phi_x)\n",
    "            Y.append(y_up_star)\n",
    "        return np.squeeze(Y)\n",
    "\n",
    "    return tfu.struct(nu=nu, C=C, predict=classifier)\n",
    "\n",
    "def train_ours(X, Y, phi, opts):\n",
    "    (nx, dx), (ny, k) = X.shape, Y.shape\n",
    "    assert nx == ny\n",
    "\n",
    "    if opts.c_mode == 'random':                                            \n",
    "        C = np.random.uniform(size=(k, k))\n",
    "    elif opts.c_mode == 'ones':\n",
    "        C = np.ones((k, k))\n",
    "    else:\n",
    "        raise ValueError('C mode: %s' % opts.mode)\n",
    "    C[range(k), range(k)] = 0\n",
    "    \n",
    "    nu = np.zeros([opts.dim_nu, 1] )\n",
    "    \n",
    "    for it in range(opts.iters):\n",
    "        loss, grad = [], []\n",
    "        for x, y_true in zip(X, Y[..., None]):\n",
    "            # solve the inner LP\n",
    "            phi_x = np.stack([\n",
    "                phi.phi(x=x[None], y=one_hot(i, k)[None])\n",
    "                for i in range(k)\n",
    "            ], axis=2)[0]\n",
    "            y_down_star, v = solve_lp_down(C, nu, phi_x, y_true)\n",
    "\n",
    "            # compute the subgradient\n",
    "            loss.append(v)\n",
    "            grad.append(np.outer(nu, y_down_star - y_true))\n",
    "            nu -= opts.alpha_nu * phi_x.dot(y_down_star - y_true)\n",
    "        loss, grad  = np.mean(loss), np.mean(grad, axis=0)\n",
    "        print it, loss,  phi.train(x=X, g=grad)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X, y = load('iris')\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "opts = tfu.struct(\n",
    "    iters=50,\n",
    "    tol=1e-5,\n",
    "    c_mode='ones',\n",
    "    \n",
    "    alpha_nu=5e-2,\n",
    "    dim_x=X.shape[1],\n",
    "    dim_y=y.shape[1],\n",
    "    dim_nu=64,\n",
    "    sizes=[],\n",
    "    \n",
    "    solver_type='Adam',\n",
    "    alpha=1e-3,\n",
    "    beta1=0.9,\n",
    "    beta2=0.999,\n",
    ")\n",
    "# features = Features(opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.667106182973 {'it': 36, 'op': None}\n",
      "1 0.666440860378 {'it': 37, 'op': None}\n",
      "2 0.665765082539 {'it': 38, 'op': None}\n",
      "3 0.66507988318 {'it': 39, 'op': None}\n",
      "4 0.664386038877 {'it': 40, 'op': None}\n",
      "5 0.663684089652 {'it': 41, 'op': None}\n",
      "6 0.662974356852 {'it': 42, 'op': None}\n",
      "7 0.662256963236 {'it': 43, 'op': None}\n",
      "8 0.661531849487 {'it': 44, 'op': None}\n",
      "9 0.660798792162 {'it': 45, 'op': None}\n",
      "10 0.660057421857 {'it': 46, 'op': None}\n",
      "11 0.659307240329 {'it': 47, 'op': None}\n",
      "12 0.658547638246 {'it': 48, 'op': None}\n",
      "13 0.657777912295 {'it': 49, 'op': None}\n",
      "14 0.656997282131 {'it': 50, 'op': None}\n",
      "15 0.656204906777 {'it': 51, 'op': None}\n",
      "16 0.655399899805 {'it': 52, 'op': None}\n",
      "17 0.654581345644 {'it': 53, 'op': None}\n",
      "18 0.653748307854 {'it': 54, 'op': None}\n",
      "19 0.652899848555 {'it': 55, 'op': None}\n",
      "20 0.652035029368 {'it': 56, 'op': None}\n",
      "21 0.651152928489 {'it': 57, 'op': None}\n",
      "22 0.650252640382 {'it': 58, 'op': None}\n",
      "23 0.64933328477 {'it': 59, 'op': None}\n",
      "24 0.649041209462 {'it': 60, 'op': None}\n",
      "25 0.649014526384 {'it': 61, 'op': None}\n",
      "26 0.6489818278 {'it': 62, 'op': None}\n",
      "27 0.648950707505 {'it': 63, 'op': None}\n",
      "28 0.64891514704 {'it': 64, 'op': None}\n",
      "29 0.648860195024 {'it': 65, 'op': None}\n",
      "30 0.648839136668 {'it': 66, 'op': None}\n",
      "31 0.648792613321 {'it': 67, 'op': None}\n",
      "32 0.648737068379 {'it': 68, 'op': None}\n",
      "33 0.648692915289 {'it': 69, 'op': None}\n",
      "34 0.64864751259 {'it': 70, 'op': None}\n",
      "35 0.648601006991 {'it': 71, 'op': None}\n",
      "36 0.648553525119 {'it': 72, 'op': None}\n",
      "37 0.64850517153 {'it': 73, 'op': None}\n",
      "38 0.648456043841 {'it': 74, 'op': None}\n",
      "39 0.648406207444 {'it': 75, 'op': None}\n",
      "40 0.648368164658 {'it': 76, 'op': None}\n",
      "41 0.648317042548 {'it': 77, 'op': None}\n",
      "42 0.648247843997 {'it': 78, 'op': None}\n",
      "43 0.648200621339 {'it': 79, 'op': None}\n",
      "44 0.648148275989 {'it': 80, 'op': None}\n",
      "45 0.648107544154 {'it': 81, 'op': None}\n",
      "46 0.6480537687 {'it': 82, 'op': None}\n",
      "47 0.647987828657 {'it': 83, 'op': None}\n",
      "48 0.647933961992 {'it': 84, 'op': None}\n",
      "49 0.647879690345 {'it': 85, 'op': None}\n"
     ]
    }
   ],
   "source": [
    "clf = train_ours(X_train, y_train, features, opts)\n",
    "# clf = train_basic(X_train, y_train, phi_basic, opts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_hat_train = clf.predict(X_train)\n",
    "train_acc = np.equal(y_hat_train.argmax(-1), y_train.argmax(-1)).mean()\n",
    "train_loss = np.einsum('bi,ij,bj->b', y_hat_train, clf.C, y_train).mean()\n",
    "\n",
    "y_hat_test = clf.predict(X_test)\n",
    "test_acc = np.equal(y_hat_test.argmax(-1), y_test.argmax(-1)).mean()\n",
    "test_loss = np.einsum('bi,ij,bj->b', y_hat_test, clf.C, y_test).mean()\n",
    "\n",
    "print 'train / test'\n",
    "print 'accuracy:', train_acc, test_acc\n",
    "print 'loss:', train_loss, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features.phi(x=X[None, 0], y=one_hot(1, 3)[None] ).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "phi = features.phi.outputs\n",
    "theta = features.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print tf.gradients(phi, theta)\n",
    "print features.param_shapes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
